---
title: "Adaptive Thresholds and Scan Statistics"
author: "Nathen Byford"
format: 
  baylor_theme-revealjs:
    footer: "Nathen Byford"
bibliography: papers.bib
biblio-style: ieee
---

```{R}
#| include: false

library("tidyverse"); theme_set(theme_minimal())
```

## Contents

1. Adaptive Thresholds [@lambert_adaptive_2006]
    i) Motivation
    i) Methods
    i) Results
2. Scan Statistics [@neil_scan_2013]
    i) Motivation
    i) Methods
    i) Results
3. New Research Idea

# Adaptive Thresholds:
Monitoring Streams of Network Counts

## Motivation {.smaller}

::::columns
:::{.column width=60%}
* Communications networks have many components that report statistics about their health on a regular basis. Daily, hourly, minutely, or even more frequent. 

* Network traffic and similar fields of interest often have data that are nonstationary and full of cyclical patterns.

* How do we measure extreme *counts* when that data is being collected so rapidly?  

* When setting these manually by treating each time period and region separately for each metric:
    * Leads to far too many thresholds to be set by hand, and
    * Far too many false alarms to be investigated.
:::

:::{.column width=40%}
![](photos/network-switch.jpg)
:::
::::
>   "The goal is to detect events with each incoming count, without looking at the past raw counts or being distracted by strong cyclical patterns, trends high background variability, or stretches of missing data."

:::{.notes}
If we set a threshold for every time period and we set it hourly, we will have 24 in a day and then 7 days in a week. This adds up to 168 thresholds on the low end for a week, and they need to be updated as we get more data. Right?
:::

## Previous methods

* Batch the data into intervals that are sufficiently short in so counts can be considered identically distributed.
    * Problem is that these intervals make it difficult to detect in real time because all analysis is done after the interval.
* Others have assumed that daily patterns repeat so that homogeneity holds not just within short intervals, but also across days. Specifically counts at the same times (Say 9:00am to 9:05am).

## New Method Requirements
* For a model that is monitoring extremes, the model must have accurate tails. (Negative-binomial distribution)
* Continuously smooth and and tracks both cyclical and long-term trends.
* Be able to capture both extreme value spikes and persistent low-level degradation.[^1]
* Threshold on a severity metric $S_t$. The severity metric could capture both the magnitude and duration of an event.

[^1]:Formulate the problem as statistical process control

## Adaptive Count Thresholding {.smaller}

Thinking in process control terms, we can standardize each count and then use an exponentially weighted moving average (EWMA) process to get an adaptive threshold.

**Adaptive count thresholding** consists of four basic steps:  

:::def
1. Interpolate the stored grid values to obtain the estimated parameters for the reference negative binomial distribution $F_t$ in effect at time $t$
2. Score $X_t$ by computing its $p$ value, $p_t$, under its reference distribution $F_t$ and its normal score $Z_t = \Phi^{-1}(p_t)$.
3. Threshold the updated severity metric, $S_t = (1 - w) \times S_{t-1} + wZ_t$, against a constant threshold
4. Update stored grid values with a count $X_t$, or with a random draw from $F_t$ if $X_t$ is missing, or with a random draw from the tail of $F_t$ if $X_t$ is an outline.
:::

## Adaptive Count Thresholding Pros

* Each step is quick to compute
* The $p$ values provide a natural way to monitor the performance
* The negative binomial distribution will provide a roughly uniform distribution on the $p$ values

## The Procedure {.smaller}

The following procedure is proposed to calculate thresholds for a time stamp $t$:

:::def
1. *Index:* obtain time stamp $t$ from the minute, hour, and day information.
2. *Compute reference parameters:* Compute the mean and variance of the reference distribution.
3. *Validate:* If the count is not missing, compute the continuity-corrected $p$ value.
4. *Threshold:* If the count is not missing, compute the normal $Z$ score under the reference distribution.
5. *Outliers and missing data:* If the count is missing, take a random draw from the reference distribution. If it's an outlier or exceeds the threshold, replace with a random tail value from the reference distribution.
6. *Update reference distribution:* Update the estimated mean and variance of the reference distribution.
7. *Update grid values:* Update the grid values for each minute.
:::

## Simulation and Results {.smaller}
::::{.columns}
:::{.column width=60%}
:::def
* The data was simulated from a negative binomial distribution with mean, $$\mu(t) = \left(1 + \frac{t}{10T}\right)\left(2e^{\sin(2 \pi a_t)} + .5e^{\sin(-8 \pi a_t)}\right)$$ and variance $\sigma^2(t) = \max\{\mu(t), \mu(t)^2 / 4\}$.  
Where $a_t = t / (24 \times 60)$.
This is shown in the plot on the right.

* Using the adaptive thresholding technique, the results for the simulation study are shown in the table to the right. We can see that the the probability of detection increases with the increase of the shift quantile.

* We see that the mean time for detection is anywhere from 3 minutes up to almost 20 minutes. 
:::
:::
:::{.column width=40%}
```{R}
#| echo: false
#| fig-width: 4
#| fig-height: 2

nb_mean <- function(t) {
    T <- 24 * 60
    a <- t / T
    (1 + t / (10 * T)) * (2 * exp(sin(2 * pi * a) + .5 * exp(sin(-8 * pi * a))))
}
h <- map(1:24, ~rep(.x, 60)) |> unlist()
tbl <- tibble(h = h, m = 1:1440, nb = nb_mean(m))

tbl |> 
  ggplot(aes(x = m/60, y = nb)) +
  geom_line() +
  scale_x_continuous(breaks = c(0, 5, 10, 15, 20)) +
  labs(title = "Mean of neg-binomial distribution", subtitle = "For hourly counts",
       x = "Time of day (hour)", y = "Neg-binomial mean")
```

![Table of Simulation Results](photos/thresholds_sim.png){width=60%}
:::
::::

# Scan Statistics 
For the Online Detection of Locally Anomalous Subgraphs

## Motivation {.smaller}
A common first step for an intrusion is to infect an initial machine on a network with a phishing attack. This initial machine is not often the target of the attack so the adversary will move through the network through internal communications since they are already inside the secured network. In the figure below we can see a graph of how one of these attacks would look.

```{mermaid}
flowchart LR
a[Intruder] .->|Phishing attack| A(Machine 1)
A --> B(Machine 2)
A ==> C(Machine 4)
A --> D(Machine 3)
C --> E(Machine 5)
C ==> F[Target]
C --> G(Machine 6)
```


## Types of Intrusions {.smaller}
::::columns
:::{.column width=60%}
There are 2 intrusion types of interest in the paper.

:::def
1. *Traversal Behavior: $k$-Paths*, seen in figure 1.

    * When an intruder goes from computer to computer with thick edges to find the next target in step 3.
    * $k$-path is a subset of nodes and edges where the size and diameter are both equal to $k$
2. *Scanning Behavior: Out Stars*, seen in figure 2.

    * When an intruder is interested in searching around a single node to find vulerabikities in neighbering computers.
    * This generates traffic stemming from a central node as seen in figure 2, this forms a star shape.
:::
:::
:::{.column width=40%}
![Figure 1: A traversal attack](photos/Traversal_attack.png){width=80%}

![Figure 2: out-star shape centered at node $v$](photos/out-star.png){width=70%}
:::
::::
This paper focuses on the traversal behavior with $k$-paths activity, utilizing a star shaped scan statistic.

:::{.notes}
In $k$-path the size is the number of edges in the subset and the diameter is the shortest directed hop-distance between any two nodes. The $k$-paths anomaly can also be called the caterpillar anomaly due to the thick path shape of it.
:::


## The Scan Statistics {.smaller}

* We are interested in the sets of two-dimensional windows in the time $\times$ graph product space.
    * A graph $G = (V, E)$ with node set $V$ and edge set $E$ is observed.
    * For each edge $e \in E$, a count process $X_e(t)$ is observed at discrete times $t \in \{1, 2, \ldots, T\}$.
* We assume that for any time $t$ and edge $e$, the edge activity $X_e(t)$ can be described with a stochastic process given by $\boldsymbol{\theta}_e(t)$.
* Let $\gamma$ be the set of windows of time we are interested in, we can determine the likelihood of the stochastic process as $L\left(\boldsymbol{\theta}(\gamma) | X(\gamma)\right)$. 
* To test the data observed versus what we expect using the stochastic process the generalized likelihood ratio test is used,

$$
\lambda_\gamma = -2 \log\left(\frac{L(\boldsymbol{\theta}_0(\gamma)| x(\gamma))}{\sup_{\theta \in \Theta_1}L\left(\boldsymbol{\theta}(\gamma)|x(\gamma)\right)}\right)
$$

Large values of $\lambda_\gamma$ indicate anomalies in the observed window $\gamma$

## Modling
There are two models looked at for the stochastic process of each edge, these:

* Observed Markov Models, and
* Hidden Markov Models.

:::{.notes}
* OMM:
This model captures the sparaticness, it ignores the distribution of the counts, and also does not reflect the underlying hidden process in many edge activities.
* HMM:
Splits the model into two parts, with a low state and high state. The high state is given a negative binomial distribution for it's good properties of detecting anomalies in count data.
:::

## Simulation

* In the simulation both star and path shapes were used to scan the data to detect anomalous edge activity.
* The simulated data included star, path, and caterpillar anomalies.

## Simulation Results {.smaller}
In the table below, there are detection statistics for the simulation study.

:::def
| Anomaly type | Scan type | AEF[^2.1] | PAD[^2.2] | GS[^2.3] |
|--------------|-----------|----:|----:|---:|
| Star         | Path      | 0.18(0.02) | 0.23(0.03) | 448.5(106.49)|
| Star         | Star      | 1.00(0.00) | 1.00(0.00) | 43.02(0.02)  |
| CatA         | Path      | 0.01(0.01) | 0.79(0.01) | 3431.71(279.11)|
| CatA         | Star      | 0.02(0.00) | 0.19(0.01) | 62.42(4.06) |
| CatB         | Path      | 0.24(0.01) | 0.92(0.01) | 887.04(106.96) |
| CatB         | Star      | 1.00(0.00) | 1.00(0.00) | 134.02(0.02) |
:::

[^2.1]: AEF is the average number of anomalous edges per number of detected edges.  
[^2.2]: PAD is the average percentage of the truly anomalous edges that were detected.  
[^2.3]: GS is the average size of the detected subgraph, which may contain many false edges.

# Potential Research

## Dynamic Thresholds for event stream counts

Take inspiration from ideas used in *dynamic memory allocation* in computer systems (machine learning algorithms) and apply these methods to help predict thresholds for a time series steaming data.   
<ins>This method would involve:</ins>  

* Using the past time series and multivariate data and a machine/statistical learning algorithm to get a prediction of the distribution of the next values.
* Using these prediction we could calculate a severity metric $S_t$ from adaptive thresholds[@lambert_adaptive_2006] and statistical process control to determine a future threshold for anomaly detection.

## Dynamic thresholds (cont.)

* Then continuously update the model as the data streams so that it continues to update the threshold based on the data.
* This method could be used for anomaly detection for any streaming data to dynamically assign the threshold used for future values.
* This model could be combined with adversarial machine learning methods to produce a robust machine learning algorithm that is not effected by the outliers.[@Insua_2023]


# Questions or comments?

## References
